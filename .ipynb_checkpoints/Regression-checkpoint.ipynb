{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression</h1>\n",
    "<h4>Design Matrix</h4>\n",
    "has the structure n x (1 + d )\n",
    "\n",
    "$ \\Phi = \\begin{pmatrix} bias & x_1^{(1)} & x_2^{(1)}& ... & x_d^{(1)}\\\\ ... & ... & ... & ... & ...\\\\ bias & x_1^{(n)} & x_2^{(n)} & ... & x_d^{(n)}\\end{pmatrix}$\n",
    "\n",
    "Linear Regression Implies\n",
    "\n",
    "$ y(w,x) = \\sum_{j=0}^{M-1}w_j\\cdot\\phi_j(x)=\\langle w|\\Phi(x) \\rangle = w^T\\cdot \\Phi(x)$\n",
    "\n",
    "The loss function used is the least-squares estimator, with the $l_2$ norm,\n",
    "\n",
    "$E(w)=\\frac{1}{2}\\cdot \\sum_{\\eta=1}^N(t_{\\eta}-w^T\\cdot x_{\\eta})^2 + \\frac{\\lambda}{2}\\lVert w \\rVert_2^2$\n",
    "\n",
    "The gradient-descent is,\n",
    "\n",
    "$\\nabla E(w)= \\nabla \\Big(\\frac{1}{2}\\cdot \\sum_{\\eta=1}^N(t_{\\eta}-w^T\\cdot \\phi_{\\eta})^2 + \\frac{\\lambda}{2}\\lVert w \\rVert_2^2\\Big) $\n",
    "\n",
    "The gradient-descent is used as a learning rule for the weight finding, the goal is to converge to an optimal solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ridge Regression</h3>\n",
    "The ridge regression uses a closed-form solution therefore we need to find a minimum of the previous loss function. This minimum can be local or global there's no way to know.\n",
    "\n",
    "Therefore the gradient is,\n",
    "\n",
    "$\\nabla E(w)= \\nabla \\Big(\\frac{1}{2}\\cdot \\sum_{\\eta=1}^N(t_{\\eta}-w^T\\cdot \\phi_{\\eta})^2 + \\frac{\\lambda}{2}\\lVert w \\rVert_2^2\\Big)=0 $\n",
    "\n",
    "$\\iff \\nabla \\Big(\\frac{1}{2}\\cdot (t-w \\cdot \\Phi)^T \\cdot (t-w \\cdot \\Phi) + \\frac{\\lambda}{2} w^Tw\\Big)=0 $\n",
    "\n",
    "$\\iff \\nabla \\Big(\\frac{1}{2}\\cdot \\big(t^Tt - t^Tw\\Phi - w^T\\Phi^Tt + w^T\\Phi^Tw\\Phi + \\lambda w^Tw\\big)\\Big)=0 $\n",
    "\n",
    "$\\iff \\frac{1}{2}\\cdot \\big( 0 - t^T\\Phi - \\Phi^Tt + 2 w\\Phi^T\\Phi + 2 \\lambda w\\big)=0 $\n",
    "\n",
    "$\\iff \\frac{1}{2}\\cdot \\big( -2 \\Phi^Tt + 2 w\\Phi^T\\Phi + 2 \\lambda w\\big)=0 $\n",
    "\n",
    "$\\iff  - \\Phi^Tt + w\\Phi^T\\Phi + \\lambda w =0 $\n",
    "\n",
    "$\\iff  \\Phi^Tt =  w\\Phi^T\\Phi + \\lambda w $\n",
    "\n",
    "$\\iff  \\Phi^Tt = \\big( \\Phi^T\\Phi + \\lambda \\cdot I \\big) w $\n",
    "\n",
    "$\\iff  w = \\big( \\Phi^T\\Phi + \\lambda \\cdot I \\big)^{-1} \\cdot \\Phi^Tt $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closed-form solution is a fixed vector of the best weights that give the minimum of the loss function (obtained from the gradient of the squared error)<p>\n",
    "Lasso does not have a closed-form soltuion because it uses an $l_1$ which does not have a derivative\n",
    "\n",
    "<h4>Ridge Regression</h4>\n",
    "Prediction with  linear models with a penalty to minimize overfitting.\n",
    "\n",
    "$ w = \\big( \\Phi^T\\Phi + \\lambda \\cdot I \\big)^{-1} \\cdot \\Phi^Tt $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "[[ 4 18 17]\n",
      " [18 94 81]\n",
      " [17 81 81]]\n",
      "+\n",
      "[[4. 0. 0.]\n",
      " [0. 4. 0.]\n",
      " [0. 0. 4.]]\n",
      ")^-1\n",
      ".\n",
      "(\n",
      "[[1 1 1 1]\n",
      " [2 4 5 7]\n",
      " [4 2 6 5]]\n",
      ".\n",
      "[1.  1.5 2.  2.5]\n",
      "=\n",
      "[[ 0.22500636 -0.0194607  -0.02645637]\n",
      " [-0.0194607   0.04973289 -0.04350038]\n",
      " [-0.02645637 -0.04350038  0.05850929]]\n",
      ".\n",
      "[ 7.  35.5 31.5]\n",
      "=\n",
      "[0.05081404 0.25903078 0.11358433]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "phi=np.array([[1,2,4],[1,4,2],[1,5,6],[1,7,5]])     #write here the design matrix values\n",
    "res1 = np.dot(phi.T,phi)\n",
    "i=np.identity(res1.shape[0])\n",
    "l2=4*i                                              #write here the lambda value                                       \n",
    "print('(')\n",
    "print(res1)\n",
    "print('+')\n",
    "print(l2)\n",
    "print(')^-1')\n",
    "\n",
    "targets=np.array([1 , 1.5 , 2 , 2.5])              #write here the target values\n",
    "print('.')\n",
    "print('(')\n",
    "print(phi.T)\n",
    "print('.')\n",
    "print(targets)\n",
    "print('=')\n",
    "inverse=np.linalg.inv(res1+l2)\n",
    "res2 = np.dot(phi.T,targets)\n",
    "print(inverse)\n",
    "print('.')\n",
    "print(res2)\n",
    "print('=')\n",
    "w = np.dot(inverse,res2)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Polynomial Regression </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "design matrix\n",
      "[[ 1  0  0]\n",
      " [ 1  1  1]\n",
      " [ 1  2  4]\n",
      " [ 1  3  9]\n",
      " [ 1  4 16]]\n",
      "weight vector\n",
      "[[ 0.88571429 -0.77142857  0.14285714]\n",
      " [-0.77142857  1.24285714 -0.28571429]\n",
      " [ 0.14285714 -0.28571429  0.07142857]] .\n",
      " [[ 1  1  1  1  1]\n",
      " [ 0  1  2  3  4]\n",
      " [ 0  1  4  9 16]] .\n",
      " [[  1]\n",
      " [  4]\n",
      " [ -4]\n",
      " [ 16]\n",
      " [-16]]\n",
      "\n",
      "w =  [[-1.4  9.8 -3. ]]\n",
      "\n",
      "y=[-1.4] x^ 0 +[9.8] x^ 1 +[-3.] x^ 2 +"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "\n",
    "X=np.array([0,1,2,3,4])                              #write here the design matrix values\n",
    "targets = np.array([1,4,-4,16,-16])\n",
    "targets = targets.reshape(-1,1)\n",
    "\n",
    "print('design matrix')\n",
    "\n",
    "degree=2                                             #regression degree\n",
    "phi = [1]*X.shape[0]\n",
    "\n",
    "phi = np.vstack((phi,X))   #add bias\n",
    "\n",
    "for i in range(2,degree+1):\n",
    "    i =pow(X,i)\n",
    "    phi = np.vstack((phi,i))\n",
    "\n",
    "phi = phi.T\n",
    "print(phi)\n",
    "\n",
    "print('weight vector')\n",
    "print(np.linalg.inv(phi.T.dot(phi)),'.\\n',phi.T,'.\\n',targets)\n",
    "\n",
    "w = np.linalg.inv(phi.T.dot(phi)).dot(phi.T).dot(targets)\n",
    "\n",
    "print('\\nw = ',w.T)\n",
    "\n",
    "print('\\ny=',end=\"\")\n",
    "\n",
    "for i in range(0,len(w)):\n",
    "    print(w[i],'x^',i,'+',end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
